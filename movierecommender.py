# -*- coding: utf-8 -*-
"""MovieRecommender.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1StK3NP5UyzcPSt7Xmc4HZO18yE8wjN33

Installs
"""

!pip install optuna

"""Imports"""

import pandas as pd
import numpy as np
import ast
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score
import kagglehub
import os
import optuna

"""Fetching dataset"""

base_path = kagglehub.dataset_download("rounakbanik/the-movies-dataset")

df = pd.read_csv(os.path.join(base_path, "movies_metadata.csv"), low_memory=False)
df.head()

"""Preprocessing"""

# Drop rows with missing or invalid data
df = df[df['vote_average'].apply(lambda x: str(x).replace('.', '', 1).isdigit())]
df = df[df['popularity'].apply(lambda x: str(x).replace('.', '', 1).isdigit())]
df = df.dropna(subset=['genres'])

# Keep only necessary columns
df = df[['id', 'title', 'genres', 'popularity', 'vote_average']]

# Convert columns
df['popularity'] = df['popularity'].astype(float)
df['vote_average'] = df['vote_average'].astype(float)

# Parse genres from JSON-like string
def parse_genres(genres_str):
    try:
        genres = ast.literal_eval(genres_str)
        return [g['name'] for g in genres]
    except:
        return []

df['genres'] = df['genres'].apply(parse_genres)

# One-hot encode genres
genres_set = list(set(g for sublist in df['genres'] for g in sublist))
for genre in genres_set:
    df[genre] = df['genres'].apply(lambda x: int(genre in x))

"""Creating a like binary label: `like = 1 if vote_average >= 7, else 0`"""

df['like'] = df['vote_average'].apply(lambda x: 1 if x >= 7 else 0)

"""Define features and target"""

features = ['popularity'] + genres_set
X = df[features]
y = df['like']

"""Train-test Split"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Evaluation metric for Optuna"""

def custom_eval_metric(y_true, y_pred):
    # Calculate all metrics
    accuracy = accuracy_score(y_true, y_pred)
    precision_1 = precision_score(y_true, y_pred, pos_label=1)
    recall_1 = recall_score(y_true, y_pred, pos_label=1)
    f1_1 = f1_score(y_true, y_pred, pos_label=1)

    # Calculate class balance
    class_ratio = sum(y_true) / len(y_true)  # % of class 1

    # Penalty if model predicts all 0s
    if sum(y_pred) == 0:
        return 0  # Worst possible score

    # Weighted score (adjust weights as needed)
    score = (
        0.5 * accuracy +
        0.2 * f1_1 +
        0.1 * recall_1 +
        0.2 * precision_1
    )

    # Additional penalty if recall_1 is below class ratio
    if recall_1 < class_ratio:
        penalty = (class_ratio - recall_1) * 0.5
        score -= penalty

    return score

"""Optuna objective function"""

def objective(trial):
    params = {
        'max_depth': trial.suggest_int('max_depth', 2, 10),
        'min_samples_split': trial.suggest_int('min_samples_split', 2, 100),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 50),
        'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 2, 20),
        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),
        'splitter': trial.suggest_categorical('splitter', ['best', 'random']),
        'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced']),
        'random_state': 42
    }

    model = DecisionTreeClassifier(**params)
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    score = custom_eval_metric(y_test, y_pred)

    return score

"""Main"""

# Create study and optimize
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

# Best trial results
print(f"Best trial score: {study.best_value:.4f}")
print("Best params:")
for key, value in study.best_params.items():
    print(f"  {key}: {value}")

# Train final model
best_model = DecisionTreeClassifier(**study.best_params, random_state=42)
best_model.fit(X_train, y_train)

"""Evaluate"""

y_pred = best_model.predict(X_test)
print("\nFinal Model Performance:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

"""Recommend movies the model thinks the user will like"""

df['predicted_like'] = best_model.predict(X)

recommended_movies = df[(df['predicted_like'] == 1)][['title', 'vote_average', 'popularity']].sort_values(
    by=['vote_average', 'popularity'], ascending=False).head(20)

print("\nðŸŽ¬ Recommended Movies:\n")
print(recommended_movies)

"""Visualize the decision tree"""

from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

plt.figure(figsize=(20,10))
plot_tree(best_model,
          feature_names=X_train.columns,  # Replace with your feature names
          class_names=['0', '1'],  # Your class labels
          filled=True,
          rounded=True,
          proportion=True,
          max_depth=3)  # Limit depth for readability
plt.title("Optimized Decision Tree")
plt.show()