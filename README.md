# ML_projects

## 1. ğŸ¬ Movie Recommender using Decision Tree and Optuna

This project builds a movie recommender system using the [Movies Dataset](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset) from Kaggle. It trains a Decision Tree Classifier to predict whether a user would "like" a movie based on its popularity and genres.

### ğŸ“Œ Features

- Binary classification: `like = 1 if vote_average â‰¥ 7, else 0`
- One-hot encoding for genres
- Uses `popularity` and `genres` as features
- Hyperparameter tuning with **Optuna**
- Model evaluation using accuracy, precision, recall, and F1-score
- Top movie recommendations based on predicted "likes"
- Visualizes optimized decision tree

### ğŸ“ Dataset

Downloaded via `kagglehub`:
- File used: `movies_metadata.csv`

### ğŸ“¦ Dependencies

pip install optuna kagglehub

### ğŸ§  Model Training

- Train-test split on preprocessed features
- Custom evaluation metric prioritizes class 1 (likes)
- Decision Tree optimized with Optuna for best generalization

### ğŸ“Š Evaluation Sample

Accuracy: 0.73

Classification Report:
              precision    recall  f1-score   support
           0       0.83       0.82      0.83      7168
           1       0.36       0.38      0.37      1893

### ğŸ¯ Movie Recommendations

Predicts which movies are likely to be liked (`predicted_like = 1`) and recommends the top 20 based on vote average and popularity.

### ğŸŒ³ Decision Tree Visualization

Plots a limited-depth decision tree to interpret model behavior and dominant features.

### ğŸ“Œ Notes

This is a baseline model. You can improve it by:
- Balancing the dataset using SMOTE or class weights
- Trying ensemble models (e.g., Random Forest)
- Incorporating additional content features (overview, cast, crew, tags)

## 2. Gold Price Predictor  

### Overview  
A deep learning model that predicts gold prices using historical data with a Convolutional Neural Network (CNN).  

### Features  
- Data preprocessing & normalization  
- CNN architecture with Conv1D layers  
- Early stopping during training  
- Evaluation metrics (MAE, RMSE)  
- 30-day future price forecasting  

### Requirements  
- Python 3.x  
- TensorFlow  
- scikit-learn  
- pandas, numpy, matplotlib  
- kagglehub  

### Usage  
1. Load and preprocess historical gold price data  
2. Split into training/test sets  
3. Train CNN model  
4. Evaluate performance  
5. Generate future predictions  

### Results  
- Price prediction vs actual visualization  
- Training/validation loss curves  
- 30-day forecast with dates  

Dataset: [Kaggle Gold Price Prediction Dataset](https://www.kaggle.com/datasets/sid321axn/gold-price-prediction-dataset) 

## 3. ğŸ“§ Spam Email Detector with TPOT AutoML

This project uses **TPOT**, an AutoML library built on top of scikit-learn, to automatically generate a high-performing machine learning pipeline for detecting spam emails. The dataset used is the publicly available **SMS Spam Collection**, which includes labeled SMS messages categorized as *spam* or *ham* (non-spam).

### ğŸ›  Features

- Automated model selection and hyperparameter tuning with TPOT
- TF-IDF vectorization of preprocessed message text
- Stopword removal and basic text cleaning
- Train-test split with stratification
- Evaluation using accuracy and classification report
- Export of the best performing pipeline to a standalone Python script

### ğŸ“‚ Dataset

The project uses the SMS Spam Collection dataset, which contains thousands of SMS messages labeled for spam detection. Each message is tagged as either "spam" or "ham" and paired with its text content.

### ğŸ“Œ Requirements

Compatible versions are used to avoid dependency conflicts, especially with numpy and scikit-learn. The project is tested in **Google Colab**, which ensures a reproducible environment.

### ğŸ“ˆ Output

After training, the notebook evaluates the model on a test set and exports the best pipeline generated by TPOT. This pipeline can be reused or deployed in other Python applications for spam classification.

### ğŸ”— Source Notebook

This project was developed in Google Colab. You can access the original notebook [here](https://colab.research.google.com/drive/17rCjbC-6Vdaxt2fJ06Pqy2-QbEdaqBzy).

## 4. ğŸ¬ SVD Recommender System with Surprise

This project implements a movie recommendation system using **Singular Value Decomposition (SVD)** from the `scikit-surprise` library. It leverages the **MovieLens dataset**, sourced directly from Kaggle, and predicts user preferences for movies based on their historical ratings.

### ğŸ›  Features

- Matrix Factorization using SVD from `scikit-surprise`
- Download of dataset via `kagglehub`
- Data loading and preprocessing with `pandas`
- Cross-validation with RMSE and MAE scoring
- Full training of the model and prediction for specific user-movie pairs

### ğŸ“‚ Dataset

The project uses the **MovieLens dataset**, which contains metadata about movies and user ratings. The following CSV files are used:

- `movies_metadata.csv`
- `ratings_small.csv`
- `links.csv`

These are automatically downloaded from Kaggle using the `kagglehub` package.

### ğŸ“Œ Requirements

To ensure compatibility, specific versions are installed:

- `numpy==1.23.5` (required for `scikit-surprise`)
- `scikit-surprise` installed from source (`--no-binary`)
- `kagglehub` for easy dataset access

This setup is tested and intended for use in **Google Colab**.

### ğŸ“ˆ Output

The notebook performs 5-fold cross-validation and reports **RMSE** and **MAE** for the SVD model. It then trains the model on the full dataset and predicts a rating for a specific user and movie.

### ğŸ”— Source Notebook

This project was developed in Google Colab. You can access the original notebook [here](https://colab.research.google.com/drive/15d37aY0uHoG_GW5w-iLcALb4OetOzf5g).


